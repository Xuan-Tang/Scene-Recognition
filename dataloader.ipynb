{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataloader.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"WE9v-J-zQaIW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650232501698,"user_tz":240,"elapsed":20603,"user":{"displayName":"Fanyue Xia","userId":"01109713640516666013"}},"outputId":"9b83c68b-74fc-43b6-9790-766f91e80a2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import Subset\n","from sklearn.model_selection import train_test_split\n","from torchvision.transforms import Compose, ToTensor, Resize\n","from torch.utils.data import DataLoader\n","from __future__ import print_function, division\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy"],"metadata":{"id":"bR0Xg9L8ZWmZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from os import path\n","from typing import Any, Callable, Dict, List, Optional, Tuple\n","from urllib.parse import urljoin\n","\n","from torchvision.datasets.folder import default_loader\n","from torchvision.datasets.utils import verify_str_arg, check_integrity, download_and_extract_archive\n","from torchvision.datasets.vision import VisionDataset\n","\n","#modify the original Places365 loader to load only data starting with a\n","class Places365c(VisionDataset):\n","    r\"\"\"`Places365 <http://places2.csail.mit.edu/index.html>`_ classification dataset.\n","\n","    Args:\n","        root (string): Root directory of the Places365 dataset.\n","        split (string, optional): The dataset split. Can be one of ``train-standard`` (default), ``train-challenge``,\n","            ``val``.\n","        small (bool, optional): If ``True``, uses the small images, i. e. resized to 256 x 256 pixels, instead of the\n","            high resolution ones.\n","        download (bool, optional): If ``True``, downloads the dataset components and places them in ``root``. Already\n","            downloaded archives are not downloaded again.\n","        transform (callable, optional): A function/transform that  takes in an PIL image\n","            and returns a transformed version. E.g, ``transforms.RandomCrop``\n","        target_transform (callable, optional): A function/transform that takes in the\n","            target and transforms it.\n","        loader (callable, optional): A function to load an image given its path.\n","\n","     Attributes:\n","        classes (list): List of the class names.\n","        class_to_idx (dict): Dict with items (class_name, class_index).\n","        imgs (list): List of (image path, class_index) tuples\n","        targets (list): The class_index value for each image in the dataset\n","\n","    Raises:\n","        RuntimeError: If ``download is False`` and the meta files, i. e. the devkit, are not present or corrupted.\n","        RuntimeError: If ``download is True`` and the image archive is already extracted.\n","    \"\"\"\n","    _SPLITS = (\"train-standard\", \"train-challenge\", \"val\")\n","    _BASE_URL = \"http://data.csail.mit.edu/places/places365/\"\n","    # {variant: (archive, md5)}\n","    _DEVKIT_META = {\n","        \"standard\": (\"filelist_places365-standard.tar\", \"35a0585fee1fa656440f3ab298f8479c\"),\n","        \"challenge\": (\"filelist_places365-challenge.tar\", \"70a8307e459c3de41690a7c76c931734\"),\n","    }\n","    # (file, md5)\n","    _CATEGORIES_META = (\"categories_places365.txt\", \"06c963b85866bd0649f97cb43dd16673\")\n","    # {split: (file, md5)}\n","    _FILE_LIST_META = {\n","        \"train-standard\": (\"places365_train_standard.txt\", \"a026646418c935c845bb4f294e6b8497\"),\n","        \"train-challenge\": (\"places365_train_challenge.txt\", \"b2931dc997b8c33c27e7329c073a6b57\"),\n","        \"val\": (\"places365_val.txt\", \"e9f2fd57bfd9d07630173f4e8708e4b1\"),\n","    }\n","    # {(split, small): (file, md5)}\n","    _IMAGES_META = {\n","        (\"train-standard\", False): (\"train_large_places365standard.tar\", \"67e186b496a84c929568076ed01a8aa1\"),\n","        (\"train-challenge\", False): (\"train_large_places365challenge.tar\", \"605f18e68e510c82b958664ea134545f\"),\n","        (\"val\", False): (\"val_large.tar\", \"9b71c4993ad89d2d8bcbdc4aef38042f\"),\n","        (\"train-standard\", True): (\"train_256_places365standard.tar\", \"53ca1c756c3d1e7809517cc47c5561c5\"),\n","        (\"train-challenge\", True): (\"train_256_places365challenge.tar\", \"741915038a5e3471ec7332404dfb64ef\"),\n","        (\"val\", True): (\"val_256.tar\", \"e27b17d8d44f4af9a78502beb927f808\"),\n","    }\n","\n","    def __init__(\n","        self,\n","        root: str,\n","        split: str = \"train-standard\",\n","        small: bool = False,\n","        download: bool = False,\n","        transform: Optional[Callable] = None,\n","        target_transform: Optional[Callable] = None,\n","        loader: Callable[[str], Any] = default_loader,\n","    ) -> None:\n","        super().__init__(root, transform=transform, target_transform=target_transform)\n","\n","        self.split = self._verify_split(split)\n","        self.small = small\n","        self.loader = loader\n","\n","        self.classes, self.class_to_idx = self.load_categories(download)\n","        self.imgs, self.targets = self.load_file_list(download)\n","\n","        if download:\n","            self.download_images()\n","\n","    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n","        file, target = self.imgs[index]\n","        image = self.loader(file)\n","\n","        if self.transforms is not None:\n","            image, target = self.transforms(image, target)\n","\n","        return image, target\n","\n","\n","    def __len__(self) -> int:\n","        return len(self.imgs)\n","\n","    @property\n","    def variant(self) -> str:\n","        return \"challenge\" if \"challenge\" in self.split else \"standard\"\n","\n","    @property\n","    def images_dir(self) -> str:\n","        size = \"256\" if self.small else \"large\"\n","        if self.split.startswith(\"train\"):\n","            dir = f\"data_{size}_{self.variant}\"\n","        else:\n","            dir = f\"{self.split}_{size}\"\n","        return path.join(self.root, dir)\n","\n","    def load_categories(self, download: bool = True) -> Tuple[List[str], Dict[str, int]]:\n","        def process(line: str) -> Tuple[str, int]:\n","            cls, idx = line.split()\n","            return cls, int(idx)\n","\n","        file, md5 = self._CATEGORIES_META\n","        file = path.join(self.root, file)\n","\n","        with open(file) as fh:\n","            class_to_idx = dict(process(line) for line in fh)\n","\n","        return sorted(class_to_idx.keys()), class_to_idx\n","\n","    def load_file_list(self, download: bool = True) -> Tuple[List[Tuple[str, int]], List[int]]:\n","        def process(line: str, sep=\"/\") -> Tuple[str, int]:\n","            image, idx = line.split()\n","            return path.join(self.images_dir, image.lstrip(sep).replace(sep, os.sep)), int(idx)\n","\n","        file, md5 = self._FILE_LIST_META[self.split]\n","        file = path.join(self.root, file)\n","        if not self._check_integrity(file, md5, download):\n","            self.download_devkit()\n","\n","        with open(file) as fh:\n","            images = [process(line) for line in fh]\n","\n","        _, targets = zip(*images)\n","        return images, list(targets)\n","\n","    def download_devkit(self) -> None:\n","        file, md5 = self._DEVKIT_META[self.variant]\n","        download_and_extract_archive(urljoin(self._BASE_URL, file), self.root, md5=md5)\n","\n","    def download_images(self) -> None:\n","        if path.exists(self.images_dir):\n","            raise RuntimeError(\n","                f\"The directory {self.images_dir} already exists. If you want to re-download or re-extract the images, \"\n","                f\"delete the directory.\"\n","            )\n","\n","        file, md5 = self._IMAGES_META[(self.split, self.small)]\n","        download_and_extract_archive(urljoin(self._BASE_URL, file), self.root, md5=md5)\n","\n","        if self.split.startswith(\"train\"):\n","            os.rename(self.images_dir.rsplit(\"_\", 1)[0], self.images_dir)\n","\n","    def extra_repr(self) -> str:\n","        return \"\\n\".join((\"Split: {split}\", \"Small: {small}\")).format(**self.__dict__)\n","\n","    def _verify_split(self, split: str) -> str:\n","        return verify_str_arg(split, \"split\", self._SPLITS)\n","\n","    def _check_integrity(self, file: str, md5: str, download: bool) -> bool:\n","        integrity = check_integrity(file, md5=md5)\n","        if not integrity and not download:\n","            raise RuntimeError(\n","                f\"The file {file} does not exist or is corrupted. You can set download=True to download it.\"\n","            )\n","        return integrity"],"metadata":{"id":"GKtls523G_5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/My\\ Drive/\n","!pwd"],"metadata":{"id":"9c2xM_onhqVw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649825432697,"user_tz":240,"elapsed":266,"user":{"displayName":"Fanyue Xia","userId":"09346053328437952788"}},"outputId":"1a5564e9-7666-4852-841c-c415c92fe2ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive\n","/content/drive/My Drive\n"]}]},{"cell_type":"code","source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","}"],"metadata":{"id":"ITJ2fvlYaJAW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.transforms.functional import to_tensor\n","train_dataset=Places365c(root=\"Places365\", small=True, download=False, transform=data_transforms[\"train\"])\n","other_dataset=Places365c(root=\"Places365\", small=True, download=False, transform=data_transforms[\"val\"])"],"metadata":{"id":"Ae8KtpMPbOvz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_val_test_dataset(train_dataset,other_dataset):\n","    train_idx, test_idx= train_test_split(list(range(len(other_dataset))), test_size=0.2,shuffle=True)\n","    datasets = {}\n","    datasets['test'] = Subset(other_dataset, test_idx)\n","    tmp_val = Subset(other_dataset, train_idx)\n","    tmp_train = Subset(train_dataset, train_idx)\n","    train_idx, val_idx = train_test_split(list(range(len(tmp_val))), test_size=0.1)\n","    datasets['train'] = Subset(tmp_train, train_idx)\n","    datasets['val'] = Subset(tmp_val, val_idx)\n","    return datasets"],"metadata":{"id":"FAX2ifb_Qm7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_test_dataset(train_dataset,other_dataset):\n","    train_idx, test_idx= train_test_split(list(range(len(other_dataset))), test_size=0.2,shuffle=True)\n","    datasets = {}\n","    datasets['test'] = Subset(other_dataset, test_idx)\n","    datasets['train'] = Subset(train_dataset, test_idx)\n","    return datasets"],"metadata":{"id":"19juQjOFs6N9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_datasets = train_test_dataset(train_dataset,other_dataset)\n","dataloaders = {x:DataLoader(image_datasets[x],batch_size=4, shuffle=True, num_workers=13) for x in ['train','test']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = [x[3:] for x in train_dataset.load_categories(False)[0]]"],"metadata":{"id":"GP32M3zqKAUR"},"execution_count":null,"outputs":[]}]}